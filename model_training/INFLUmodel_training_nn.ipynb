{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from protein_encoding import PC_6, read_fasta\n",
    "from model_tools import split, show_train_history, metric_array\n",
    "from Influ_model_edit import train_model\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "# PC6 encoding\n",
    "Influ_AVP_data = PC_6('../data/AVP4Influ.fasta', length=50)\n",
    "non_influ_AVP_data = PC_6('../data/combined_16995_negativeset.fasta', length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to np array\n",
    "AVP_array= np.array(list(Influ_AVP_data.values()))\n",
    "non_AVP_array = np.array(list(non_influ_AVP_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "non_AVP_array = random.sample(list(non_AVP_array), len(AVP_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature & labels (0:non_AVP, 1:AVP)\n",
    "features = np.concatenate((non_AVP_array,AVP_array),axis=0)\n",
    "labels = np.hstack((np.repeat(0, len(non_AVP_array)),np.repeat(1, len(AVP_array))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "train_data, val_data, train_labels, val_labels = split(features, labels , save = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "train_data, train_labels = shuffle(train_data, train_labels, random_state=0)\n",
    "val_data, val_labels = shuffle(val_data, val_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 10.1165 - accuracy: 0.5000\n",
      "Epoch 00001: val_loss improved from inf to 1.60722, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 5s 89ms/step - loss: 10.1165 - accuracy: 0.5000 - val_loss: 1.6072 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 2/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 9.6124 - accuracy: 0.4917\n",
      "Epoch 00002: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 9.4691 - accuracy: 0.5000 - val_loss: 1.6181 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 3/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 8.9681 - accuracy: 0.5091\n",
      "Epoch 00003: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 9.0692 - accuracy: 0.5000 - val_loss: 1.6448 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 4/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 8.0560 - accuracy: 0.5364\n",
      "Epoch 00004: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 8.5789 - accuracy: 0.5000 - val_loss: 1.6791 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 5/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 8.5658 - accuracy: 0.4917\n",
      "Epoch 00005: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 8.4396 - accuracy: 0.5000 - val_loss: 1.7252 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 6/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 8.5143 - accuracy: 0.4727\n",
      "Epoch 00006: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 8.0924 - accuracy: 0.5000 - val_loss: 1.7932 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 7.5360 - accuracy: 0.5000\n",
      "Epoch 00007: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 7.5360 - accuracy: 0.5000 - val_loss: 1.8836 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 7.6271 - accuracy: 0.5000\n",
      "Epoch 00008: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 7.6271 - accuracy: 0.5000 - val_loss: 1.9904 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 6.5428 - accuracy: 0.5000\n",
      "Epoch 00009: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 6.5428 - accuracy: 0.5000 - val_loss: 2.0846 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 10/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 6.2791 - accuracy: 0.4818\n",
      "Epoch 00010: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 6.0824 - accuracy: 0.5000 - val_loss: 2.1582 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 11/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 5.7452 - accuracy: 0.5000\n",
      "Epoch 00011: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 5.7812 - accuracy: 0.5000 - val_loss: 2.2143 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 5.3192 - accuracy: 0.5000\n",
      "Epoch 00012: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 5.3192 - accuracy: 0.5000 - val_loss: 2.2536 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 5.0830 - accuracy: 0.5246\n",
      "Epoch 00013: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 5.0830 - accuracy: 0.5246 - val_loss: 2.2627 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 14/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 4.6077 - accuracy: 0.5250\n",
      "Epoch 00014: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 4.6571 - accuracy: 0.5246 - val_loss: 2.2626 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.7971 - accuracy: 0.5246\n",
      "Epoch 00015: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 4.7971 - accuracy: 0.5246 - val_loss: 2.2632 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 16/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 4.2442 - accuracy: 0.5667\n",
      "Epoch 00016: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 4.4279 - accuracy: 0.5574 - val_loss: 2.2877 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 17/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 4.3504 - accuracy: 0.5417\n",
      "Epoch 00017: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 4.2934 - accuracy: 0.5492 - val_loss: 2.3073 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 18/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 4.1070 - accuracy: 0.5833\n",
      "Epoch 00018: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 4.2361 - accuracy: 0.5738 - val_loss: 2.3361 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 19/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 3.8866 - accuracy: 0.5300\n",
      "Epoch 00019: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 3.7983 - accuracy: 0.5492 - val_loss: 2.3556 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 20/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.3898 - accuracy: 0.5818\n",
      "Epoch 00020: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 3.6481 - accuracy: 0.5574 - val_loss: 2.3775 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 21/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 3.7498 - accuracy: 0.5900\n",
      "Epoch 00021: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 4.0544 - accuracy: 0.5656 - val_loss: 2.4068 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 22/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.5657 - accuracy: 0.5727\n",
      "Epoch 00022: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.6679 - accuracy: 0.5656 - val_loss: 2.4177 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 3.7150 - accuracy: 0.6148\n",
      "Epoch 00023: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 3.7150 - accuracy: 0.6148 - val_loss: 2.4410 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 24/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 3.8193 - accuracy: 0.5100\n",
      "Epoch 00024: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.6563 - accuracy: 0.5492 - val_loss: 2.4413 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 25/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 3.3613 - accuracy: 0.6167\n",
      "Epoch 00025: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.3396 - accuracy: 0.6148 - val_loss: 2.4538 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 26/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.2503 - accuracy: 0.6091\n",
      "Epoch 00026: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 3.6782 - accuracy: 0.5656 - val_loss: 2.4691 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 27/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.2431 - accuracy: 0.6000\n",
      "Epoch 00027: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.1641 - accuracy: 0.6066 - val_loss: 2.4644 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 28/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.2192 - accuracy: 0.5818\n",
      "Epoch 00028: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 3.2683 - accuracy: 0.5738 - val_loss: 2.4371 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 29/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.9409 - accuracy: 0.6273\n",
      "Epoch 00029: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.9963 - accuracy: 0.6148 - val_loss: 2.4176 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 30/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 3.2597 - accuracy: 0.6000\n",
      "Epoch 00030: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 3.2143 - accuracy: 0.6066 - val_loss: 2.4062 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 31/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.7775 - accuracy: 0.5917\n",
      "Epoch 00031: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.8814 - accuracy: 0.5820 - val_loss: 2.3934 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 32/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.9692 - accuracy: 0.6583\n",
      "Epoch 00032: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 3.0010 - accuracy: 0.6557 - val_loss: 2.3516 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 33/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.7824 - accuracy: 0.6091\n",
      "Epoch 00033: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 3.0372 - accuracy: 0.5902 - val_loss: 2.3432 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 34/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.7288 - accuracy: 0.6167\n",
      "Epoch 00034: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.8793 - accuracy: 0.6066 - val_loss: 2.3815 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 35/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 3.0574 - accuracy: 0.6182\n",
      "Epoch 00035: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 3.0461 - accuracy: 0.6311 - val_loss: 2.3899 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 36/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.5882 - accuracy: 0.6818\n",
      "Epoch 00036: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.9180 - accuracy: 0.6475 - val_loss: 2.4040 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.8849 - accuracy: 0.6475\n",
      "Epoch 00037: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.8849 - accuracy: 0.6475 - val_loss: 2.3791 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.6885 - accuracy: 0.6639\n",
      "Epoch 00038: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.6885 - accuracy: 0.6639 - val_loss: 2.3532 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.5733 - accuracy: 0.6885\n",
      "Epoch 00039: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.5733 - accuracy: 0.6885 - val_loss: 2.3245 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.5287 - accuracy: 0.6148\n",
      "Epoch 00040: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.5287 - accuracy: 0.6148 - val_loss: 2.2953 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 41/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.5289 - accuracy: 0.6583\n",
      "Epoch 00041: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.5022 - accuracy: 0.6639 - val_loss: 2.2377 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 42/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.5271 - accuracy: 0.7182\n",
      "Epoch 00042: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.5118 - accuracy: 0.7131 - val_loss: 2.2072 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2610 - accuracy: 0.6885\n",
      "Epoch 00043: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 2.2610 - accuracy: 0.6885 - val_loss: 2.1610 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 44/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 2.4669 - accuracy: 0.6400\n",
      "Epoch 00044: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.5162 - accuracy: 0.6393 - val_loss: 2.1293 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 45/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3130 - accuracy: 0.6583\n",
      "Epoch 00045: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.3128 - accuracy: 0.6475 - val_loss: 2.1105 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.7881 - accuracy: 0.6230\n",
      "Epoch 00046: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.7881 - accuracy: 0.6230 - val_loss: 2.0753 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 47/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.1409 - accuracy: 0.7083\n",
      "Epoch 00047: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.1600 - accuracy: 0.6967 - val_loss: 2.0115 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 48/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.2310 - accuracy: 0.6917\n",
      "Epoch 00048: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.2578 - accuracy: 0.6885 - val_loss: 2.0121 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 49/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.2062 - accuracy: 0.6583\n",
      "Epoch 00049: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.3839 - accuracy: 0.6475 - val_loss: 1.9974 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.3777 - accuracy: 0.6639\n",
      "Epoch 00050: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.3777 - accuracy: 0.6639 - val_loss: 2.0380 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 51/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 2.1106 - accuracy: 0.7100\n",
      "Epoch 00051: val_loss did not improve from 1.60722\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.2886 - accuracy: 0.6885 - val_loss: 2.0229 - val_accuracy: 0.5714 - lr: 2.0000e-04\n",
      "Epoch 52/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3657 - accuracy: 0.6750\n",
      "Epoch 00052: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.3735 - accuracy: 0.6721 - val_loss: 1.9831 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 53/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 2.1869 - accuracy: 0.6800\n",
      "Epoch 00053: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 2.0753 - accuracy: 0.7049 - val_loss: 1.9293 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.0767 - accuracy: 0.7213\n",
      "Epoch 00054: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.0767 - accuracy: 0.7213 - val_loss: 1.9022 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 55/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.8001 - accuracy: 0.7500\n",
      "Epoch 00055: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.7848 - accuracy: 0.7541 - val_loss: 1.8531 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 56/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 2.4831 - accuracy: 0.6400\n",
      "Epoch 00056: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 2.3134 - accuracy: 0.6721 - val_loss: 1.8047 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 57/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.1023 - accuracy: 0.6500\n",
      "Epoch 00057: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.2267 - accuracy: 0.6393 - val_loss: 1.8046 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.4086 - accuracy: 0.6639\n",
      "Epoch 00058: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.4086 - accuracy: 0.6639 - val_loss: 1.7902 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.3010 - accuracy: 0.6639\n",
      "Epoch 00059: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.3010 - accuracy: 0.6639 - val_loss: 1.7743 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 60/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.0997 - accuracy: 0.7000\n",
      "Epoch 00060: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.0618 - accuracy: 0.7049 - val_loss: 1.7482 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2068 - accuracy: 0.6721\n",
      "Epoch 00061: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.2068 - accuracy: 0.6721 - val_loss: 1.7168 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2013 - accuracy: 0.6967\n",
      "Epoch 00062: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.2013 - accuracy: 0.6967 - val_loss: 1.6801 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2370 - accuracy: 0.6557\n",
      "Epoch 00063: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.2370 - accuracy: 0.6557 - val_loss: 1.6694 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2807 - accuracy: 0.6967\n",
      "Epoch 00064: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.2807 - accuracy: 0.6967 - val_loss: 1.6479 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.1942 - accuracy: 0.6967\n",
      "Epoch 00065: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.1942 - accuracy: 0.6967 - val_loss: 1.6470 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 66/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.5684 - accuracy: 0.6667\n",
      "Epoch 00066: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.6451 - accuracy: 0.6639 - val_loss: 1.6675 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.0772 - accuracy: 0.6885\n",
      "Epoch 00067: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.0772 - accuracy: 0.6885 - val_loss: 1.6924 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 68/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.3526 - accuracy: 0.6833\n",
      "Epoch 00068: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.3282 - accuracy: 0.6885 - val_loss: 1.6978 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.0447 - accuracy: 0.7377\n",
      "Epoch 00069: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.0447 - accuracy: 0.7377 - val_loss: 1.7033 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2309 - accuracy: 0.7131\n",
      "Epoch 00070: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.2309 - accuracy: 0.7131 - val_loss: 1.7026 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.9282 - accuracy: 0.7417\n",
      "Epoch 00071: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.0154 - accuracy: 0.7295 - val_loss: 1.7004 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.1049 - accuracy: 0.7636\n",
      "Epoch 00072: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.0827 - accuracy: 0.7541 - val_loss: 1.6919 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.9318 - accuracy: 0.7295\n",
      "Epoch 00073: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.9318 - accuracy: 0.7295 - val_loss: 1.6731 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.1093 - accuracy: 0.7000\n",
      "Epoch 00074: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.1705 - accuracy: 0.6967 - val_loss: 1.6661 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.1529 - accuracy: 0.7131\n",
      "Epoch 00075: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.1529 - accuracy: 0.7131 - val_loss: 1.6542 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.3789 - accuracy: 0.6967\n",
      "Epoch 00076: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.3789 - accuracy: 0.6967 - val_loss: 1.6439 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 77/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.9095 - accuracy: 0.7667\n",
      "Epoch 00077: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.9131 - accuracy: 0.7623 - val_loss: 1.6328 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 78/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.0103 - accuracy: 0.6917\n",
      "Epoch 00078: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.1676 - accuracy: 0.6885 - val_loss: 1.6243 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 79/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.8373 - accuracy: 0.7636\n",
      "Epoch 00079: val_loss did not improve from 1.60722\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.8393 - accuracy: 0.7705 - val_loss: 1.6077 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2052 - accuracy: 0.6721\n",
      "Epoch 00080: val_loss improved from 1.60722 to 1.59470, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 2.2052 - accuracy: 0.6721 - val_loss: 1.5947 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 81/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.9643 - accuracy: 0.7000\n",
      "Epoch 00081: val_loss improved from 1.59470 to 1.57869, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.9565 - accuracy: 0.6967 - val_loss: 1.5787 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 82/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6470 - accuracy: 0.7167\n",
      "Epoch 00082: val_loss did not improve from 1.57869\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.7455 - accuracy: 0.7049 - val_loss: 1.5861 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6668 - accuracy: 0.7705\n",
      "Epoch 00083: val_loss improved from 1.57869 to 1.56364, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.6668 - accuracy: 0.7705 - val_loss: 1.5636 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 84/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.8669 - accuracy: 0.7000\n",
      "Epoch 00084: val_loss improved from 1.56364 to 1.54141, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.8970 - accuracy: 0.6967 - val_loss: 1.5414 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 85/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 2.1235 - accuracy: 0.6636\n",
      "Epoch 00085: val_loss improved from 1.54141 to 1.51902, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 2.1241 - accuracy: 0.6639 - val_loss: 1.5190 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7179 - accuracy: 0.7541\n",
      "Epoch 00086: val_loss improved from 1.51902 to 1.51349, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.7179 - accuracy: 0.7541 - val_loss: 1.5135 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 87/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.8515 - accuracy: 0.7273\n",
      "Epoch 00087: val_loss did not improve from 1.51349\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.9126 - accuracy: 0.7213 - val_loss: 1.5144 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 88/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7095 - accuracy: 0.7583\n",
      "Epoch 00088: val_loss improved from 1.51349 to 1.50464, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.6966 - accuracy: 0.7623 - val_loss: 1.5046 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 89/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.9792 - accuracy: 0.7182\n",
      "Epoch 00089: val_loss improved from 1.50464 to 1.49339, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.9949 - accuracy: 0.7049 - val_loss: 1.4934 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 90/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.9737 - accuracy: 0.6750\n",
      "Epoch 00090: val_loss improved from 1.49339 to 1.47940, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 2.0190 - accuracy: 0.6721 - val_loss: 1.4794 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 91/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7734 - accuracy: 0.7182\n",
      "Epoch 00091: val_loss improved from 1.47940 to 1.47579, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.7466 - accuracy: 0.7295 - val_loss: 1.4758 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 92/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7889 - accuracy: 0.7583\n",
      "Epoch 00092: val_loss improved from 1.47579 to 1.45140, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.7736 - accuracy: 0.7623 - val_loss: 1.4514 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8573 - accuracy: 0.7295\n",
      "Epoch 00093: val_loss improved from 1.45140 to 1.44334, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.8573 - accuracy: 0.7295 - val_loss: 1.4433 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 94/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7057 - accuracy: 0.7182\n",
      "Epoch 00094: val_loss improved from 1.44334 to 1.43332, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.7633 - accuracy: 0.7049 - val_loss: 1.4333 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 95/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.8668 - accuracy: 0.7333\n",
      "Epoch 00095: val_loss improved from 1.43332 to 1.42515, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.8518 - accuracy: 0.7377 - val_loss: 1.4252 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.9487 - accuracy: 0.7295\n",
      "Epoch 00096: val_loss improved from 1.42515 to 1.42120, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.9487 - accuracy: 0.7295 - val_loss: 1.4212 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 97/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.8266 - accuracy: 0.7250\n",
      "Epoch 00097: val_loss improved from 1.42120 to 1.41962, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.8108 - accuracy: 0.7295 - val_loss: 1.4196 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 98/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.8020 - accuracy: 0.7636\n",
      "Epoch 00098: val_loss improved from 1.41962 to 1.40685, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.8614 - accuracy: 0.7459 - val_loss: 1.4069 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7917 - accuracy: 0.7459\n",
      "Epoch 00099: val_loss improved from 1.40685 to 1.40319, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.7917 - accuracy: 0.7459 - val_loss: 1.4032 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7067 - accuracy: 0.7213\n",
      "Epoch 00100: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.7067 - accuracy: 0.7213 - val_loss: 1.4168 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 101/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.9134 - accuracy: 0.7250\n",
      "Epoch 00101: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.9384 - accuracy: 0.7213 - val_loss: 1.4190 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 102/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.6745 - accuracy: 0.7900\n",
      "Epoch 00102: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.6895 - accuracy: 0.7787 - val_loss: 1.4167 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 103/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7535 - accuracy: 0.7455\n",
      "Epoch 00103: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.7466 - accuracy: 0.7541 - val_loss: 1.4225 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 104/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 2.0034 - accuracy: 0.6917\n",
      "Epoch 00104: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.9848 - accuracy: 0.6967 - val_loss: 1.4192 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 105/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.9436 - accuracy: 0.6727\n",
      "Epoch 00105: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.9150 - accuracy: 0.6803 - val_loss: 1.4093 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 106/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7979 - accuracy: 0.7250\n",
      "Epoch 00106: val_loss did not improve from 1.40319\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.7896 - accuracy: 0.7213 - val_loss: 1.4106 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 107/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7769 - accuracy: 0.7182\n",
      "Epoch 00107: val_loss improved from 1.40319 to 1.39800, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.7354 - accuracy: 0.7213 - val_loss: 1.3980 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 108/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7705 - accuracy: 0.7273\n",
      "Epoch 00108: val_loss improved from 1.39800 to 1.39551, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.7375 - accuracy: 0.7377 - val_loss: 1.3955 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8816 - accuracy: 0.7295\n",
      "Epoch 00109: val_loss improved from 1.39551 to 1.38840, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.8816 - accuracy: 0.7295 - val_loss: 1.3884 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7508 - accuracy: 0.7705\n",
      "Epoch 00110: val_loss improved from 1.38840 to 1.38525, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.7508 - accuracy: 0.7705 - val_loss: 1.3852 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 111/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6680 - accuracy: 0.7500\n",
      "Epoch 00111: val_loss improved from 1.38525 to 1.38366, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.6553 - accuracy: 0.7541 - val_loss: 1.3837 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7855 - accuracy: 0.7541\n",
      "Epoch 00112: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.7855 - accuracy: 0.7541 - val_loss: 1.3863 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 113/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6665 - accuracy: 0.7583\n",
      "Epoch 00113: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.7763 - accuracy: 0.7541 - val_loss: 1.4004 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 114/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.5884 - accuracy: 0.7750\n",
      "Epoch 00114: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5763 - accuracy: 0.7787 - val_loss: 1.4102 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 115/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4700 - accuracy: 0.8000\n",
      "Epoch 00115: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5605 - accuracy: 0.7869 - val_loss: 1.4104 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 116/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5964 - accuracy: 0.7818\n",
      "Epoch 00116: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5478 - accuracy: 0.7951 - val_loss: 1.4121 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 117/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6230 - accuracy: 0.7909\n",
      "Epoch 00117: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.5615 - accuracy: 0.8033 - val_loss: 1.4075 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8284 - accuracy: 0.7705\n",
      "Epoch 00118: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.8284 - accuracy: 0.7705 - val_loss: 1.3993 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6289 - accuracy: 0.7541\n",
      "Epoch 00119: val_loss did not improve from 1.38366\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6289 - accuracy: 0.7541 - val_loss: 1.3881 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5557 - accuracy: 0.8197\n",
      "Epoch 00120: val_loss improved from 1.38366 to 1.37229, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.5557 - accuracy: 0.8197 - val_loss: 1.3723 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 121/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7772 - accuracy: 0.7167\n",
      "Epoch 00121: val_loss improved from 1.37229 to 1.36235, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.7660 - accuracy: 0.7213 - val_loss: 1.3623 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 122/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7258 - accuracy: 0.7909\n",
      "Epoch 00122: val_loss improved from 1.36235 to 1.35457, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.7589 - accuracy: 0.7951 - val_loss: 1.3546 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 123/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7287 - accuracy: 0.7250\n",
      "Epoch 00123: val_loss did not improve from 1.35457\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.7147 - accuracy: 0.7295 - val_loss: 1.3606 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 124/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.5421 - accuracy: 0.7900\n",
      "Epoch 00124: val_loss did not improve from 1.35457\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.6267 - accuracy: 0.7787 - val_loss: 1.3597 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 125/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6244 - accuracy: 0.7818\n",
      "Epoch 00125: val_loss did not improve from 1.35457\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.6237 - accuracy: 0.7705 - val_loss: 1.3554 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 126/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5669 - accuracy: 0.8273\n",
      "Epoch 00126: val_loss improved from 1.35457 to 1.35142, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.5412 - accuracy: 0.8279 - val_loss: 1.3514 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 127/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6727 - accuracy: 0.7833\n",
      "Epoch 00127: val_loss improved from 1.35142 to 1.34960, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.6594 - accuracy: 0.7869 - val_loss: 1.3496 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5699 - accuracy: 0.7541\n",
      "Epoch 00128: val_loss improved from 1.34960 to 1.34822, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.5699 - accuracy: 0.7541 - val_loss: 1.3482 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 129/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6344 - accuracy: 0.7545\n",
      "Epoch 00129: val_loss did not improve from 1.34822\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.5827 - accuracy: 0.7541 - val_loss: 1.3570 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6362 - accuracy: 0.7623\n",
      "Epoch 00130: val_loss did not improve from 1.34822\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6362 - accuracy: 0.7623 - val_loss: 1.3653 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6099 - accuracy: 0.7377\n",
      "Epoch 00131: val_loss did not improve from 1.34822\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6099 - accuracy: 0.7377 - val_loss: 1.3628 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6395 - accuracy: 0.7049\n",
      "Epoch 00132: val_loss did not improve from 1.34822\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.6395 - accuracy: 0.7049 - val_loss: 1.3529 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 133/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6157 - accuracy: 0.7636\n",
      "Epoch 00133: val_loss improved from 1.34822 to 1.34377, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.5505 - accuracy: 0.7869 - val_loss: 1.3438 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 134/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.7572 - accuracy: 0.7182\n",
      "Epoch 00134: val_loss improved from 1.34377 to 1.34075, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.6948 - accuracy: 0.7377 - val_loss: 1.3408 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6639 - accuracy: 0.6967\n",
      "Epoch 00135: val_loss improved from 1.34075 to 1.33975, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.6639 - accuracy: 0.6967 - val_loss: 1.3398 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 136/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7414 - accuracy: 0.7250\n",
      "Epoch 00136: val_loss improved from 1.33975 to 1.33644, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.7268 - accuracy: 0.7295 - val_loss: 1.3364 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 137/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.5480 - accuracy: 0.7583\n",
      "Epoch 00137: val_loss improved from 1.33644 to 1.32408, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.5453 - accuracy: 0.7541 - val_loss: 1.3241 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5800 - accuracy: 0.7869\n",
      "Epoch 00138: val_loss did not improve from 1.32408\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.5800 - accuracy: 0.7869 - val_loss: 1.3288 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 139/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5190 - accuracy: 0.7727\n",
      "Epoch 00139: val_loss improved from 1.32408 to 1.31859, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.6340 - accuracy: 0.7459 - val_loss: 1.3186 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5847 - accuracy: 0.7623\n",
      "Epoch 00140: val_loss improved from 1.31859 to 1.31771, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.5847 - accuracy: 0.7623 - val_loss: 1.3177 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 141/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.5779 - accuracy: 0.7500\n",
      "Epoch 00141: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.5352 - accuracy: 0.7623 - val_loss: 1.3236 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6997 - accuracy: 0.7541\n",
      "Epoch 00142: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.6997 - accuracy: 0.7541 - val_loss: 1.3231 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 0.7459\n",
      "Epoch 00143: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.5882 - accuracy: 0.7459 - val_loss: 1.3238 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 144/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3937 - accuracy: 0.7455\n",
      "Epoch 00144: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.3862 - accuracy: 0.7541 - val_loss: 1.3215 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 145/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6311 - accuracy: 0.7750\n",
      "Epoch 00145: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.7286 - accuracy: 0.7623 - val_loss: 1.3299 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 146/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.5774 - accuracy: 0.7500\n",
      "Epoch 00146: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5655 - accuracy: 0.7541 - val_loss: 1.3264 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 147/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4769 - accuracy: 0.7667\n",
      "Epoch 00147: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4919 - accuracy: 0.7623 - val_loss: 1.3269 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 148/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4686 - accuracy: 0.7833\n",
      "Epoch 00148: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4592 - accuracy: 0.7869 - val_loss: 1.3231 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 149/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6056 - accuracy: 0.7727\n",
      "Epoch 00149: val_loss did not improve from 1.31771\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6509 - accuracy: 0.7705 - val_loss: 1.3192 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 150/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3942 - accuracy: 0.8000\n",
      "Epoch 00150: val_loss improved from 1.31771 to 1.31323, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.3905 - accuracy: 0.8033 - val_loss: 1.3132 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6559 - accuracy: 0.7623\n",
      "Epoch 00151: val_loss improved from 1.31323 to 1.30390, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.6559 - accuracy: 0.7623 - val_loss: 1.3039 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4913 - accuracy: 0.7951\n",
      "Epoch 00152: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.4913 - accuracy: 0.7951 - val_loss: 1.3092 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 153/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.5057 - accuracy: 0.7700\n",
      "Epoch 00153: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.5315 - accuracy: 0.7623 - val_loss: 1.3052 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 154/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.6355 - accuracy: 0.7727\n",
      "Epoch 00154: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.6470 - accuracy: 0.7787 - val_loss: 1.3086 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 155/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4937 - accuracy: 0.7833\n",
      "Epoch 00155: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4832 - accuracy: 0.7869 - val_loss: 1.3123 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 156/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3743 - accuracy: 0.8083\n",
      "Epoch 00156: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4189 - accuracy: 0.7951 - val_loss: 1.3115 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4264 - accuracy: 0.8361\n",
      "Epoch 00157: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.4264 - accuracy: 0.8361 - val_loss: 1.3073 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 158/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.4609 - accuracy: 0.7909\n",
      "Epoch 00158: val_loss did not improve from 1.30390\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.5245 - accuracy: 0.7869 - val_loss: 1.3040 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3384 - accuracy: 0.8115\n",
      "Epoch 00159: val_loss improved from 1.30390 to 1.30099, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.3384 - accuracy: 0.8115 - val_loss: 1.3010 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4185 - accuracy: 0.7951\n",
      "Epoch 00160: val_loss improved from 1.30099 to 1.29669, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.4185 - accuracy: 0.7951 - val_loss: 1.2967 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 161/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3723 - accuracy: 0.8417\n",
      "Epoch 00161: val_loss did not improve from 1.29669\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4893 - accuracy: 0.8279 - val_loss: 1.3039 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 162/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1785 - accuracy: 0.8727\n",
      "Epoch 00162: val_loss did not improve from 1.29669\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1840 - accuracy: 0.8525 - val_loss: 1.3056 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5014 - accuracy: 0.7295\n",
      "Epoch 00163: val_loss did not improve from 1.29669\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5014 - accuracy: 0.7295 - val_loss: 1.3003 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 164/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5309 - accuracy: 0.7455\n",
      "Epoch 00164: val_loss improved from 1.29669 to 1.29311, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.4915 - accuracy: 0.7623 - val_loss: 1.2931 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 165/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4448 - accuracy: 0.8250\n",
      "Epoch 00165: val_loss improved from 1.29311 to 1.28191, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.4671 - accuracy: 0.8197 - val_loss: 1.2819 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 166/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5569 - accuracy: 0.7909\n",
      "Epoch 00166: val_loss improved from 1.28191 to 1.27248, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.5538 - accuracy: 0.7869 - val_loss: 1.2725 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5718 - accuracy: 0.7541\n",
      "Epoch 00167: val_loss improved from 1.27248 to 1.25655, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.5718 - accuracy: 0.7541 - val_loss: 1.2565 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3741 - accuracy: 0.8197\n",
      "Epoch 00168: val_loss improved from 1.25655 to 1.25510, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.3741 - accuracy: 0.8197 - val_loss: 1.2551 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 169/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4630 - accuracy: 0.8083\n",
      "Epoch 00169: val_loss did not improve from 1.25510\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4784 - accuracy: 0.8033 - val_loss: 1.2614 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5479 - accuracy: 0.7787\n",
      "Epoch 00170: val_loss improved from 1.25510 to 1.25341, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.5479 - accuracy: 0.7787 - val_loss: 1.2534 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 171/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4324 - accuracy: 0.8000\n",
      "Epoch 00171: val_loss improved from 1.25341 to 1.25100, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.4387 - accuracy: 0.7951 - val_loss: 1.2510 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 172/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3224 - accuracy: 0.8000\n",
      "Epoch 00172: val_loss improved from 1.25100 to 1.24621, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.3587 - accuracy: 0.7869 - val_loss: 1.2462 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 173/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3615 - accuracy: 0.8250\n",
      "Epoch 00173: val_loss improved from 1.24621 to 1.24514, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.3587 - accuracy: 0.8279 - val_loss: 1.2451 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 174/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.7052 - accuracy: 0.7333\n",
      "Epoch 00174: val_loss did not improve from 1.24514\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6913 - accuracy: 0.7377 - val_loss: 1.2471 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 175/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3489 - accuracy: 0.7727\n",
      "Epoch 00175: val_loss improved from 1.24514 to 1.24074, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.3193 - accuracy: 0.7787 - val_loss: 1.2407 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 176/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.5429 - accuracy: 0.7667\n",
      "Epoch 00176: val_loss improved from 1.24074 to 1.23554, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.5568 - accuracy: 0.7623 - val_loss: 1.2355 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4107 - accuracy: 0.8197\n",
      "Epoch 00177: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.4107 - accuracy: 0.8197 - val_loss: 1.2373 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 0.7869\n",
      "Epoch 00178: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.5239 - accuracy: 0.7869 - val_loss: 1.2404 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4294 - accuracy: 0.7869\n",
      "Epoch 00179: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.4294 - accuracy: 0.7869 - val_loss: 1.2411 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 180/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4440 - accuracy: 0.7750\n",
      "Epoch 00180: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4543 - accuracy: 0.7705 - val_loss: 1.2366 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4006 - accuracy: 0.8033\n",
      "Epoch 00181: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.4006 - accuracy: 0.8033 - val_loss: 1.2371 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 182/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4829 - accuracy: 0.7917\n",
      "Epoch 00182: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.4759 - accuracy: 0.7951 - val_loss: 1.2379 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3982 - accuracy: 0.8033\n",
      "Epoch 00183: val_loss did not improve from 1.23554\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.3982 - accuracy: 0.8033 - val_loss: 1.2363 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3269 - accuracy: 0.8197\n",
      "Epoch 00184: val_loss improved from 1.23554 to 1.23483, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.3269 - accuracy: 0.8197 - val_loss: 1.2348 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4328 - accuracy: 0.8033\n",
      "Epoch 00185: val_loss did not improve from 1.23483\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.4328 - accuracy: 0.8033 - val_loss: 1.2377 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4187 - accuracy: 0.7787\n",
      "Epoch 00186: val_loss improved from 1.23483 to 1.22989, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.4187 - accuracy: 0.7787 - val_loss: 1.2299 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 187/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4228 - accuracy: 0.7750\n",
      "Epoch 00187: val_loss improved from 1.22989 to 1.22431, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.4139 - accuracy: 0.7787 - val_loss: 1.2243 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 188/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3565 - accuracy: 0.8000\n",
      "Epoch 00188: val_loss improved from 1.22431 to 1.22125, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.3759 - accuracy: 0.7951 - val_loss: 1.2212 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3439 - accuracy: 0.8361\n",
      "Epoch 00189: val_loss improved from 1.22125 to 1.22061, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.3439 - accuracy: 0.8361 - val_loss: 1.2206 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6280 - accuracy: 0.7377\n",
      "Epoch 00190: val_loss improved from 1.22061 to 1.21646, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.6280 - accuracy: 0.7377 - val_loss: 1.2165 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 191/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5413 - accuracy: 0.7818\n",
      "Epoch 00191: val_loss improved from 1.21646 to 1.21085, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.5094 - accuracy: 0.7951 - val_loss: 1.2108 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 192/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.4674 - accuracy: 0.7818\n",
      "Epoch 00192: val_loss improved from 1.21085 to 1.20586, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.4428 - accuracy: 0.7951 - val_loss: 1.2059 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 193/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3901 - accuracy: 0.8083\n",
      "Epoch 00193: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3812 - accuracy: 0.8115 - val_loss: 1.2078 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 194/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5197 - accuracy: 0.7727\n",
      "Epoch 00194: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4626 - accuracy: 0.7951 - val_loss: 1.2071 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4821 - accuracy: 0.7869\n",
      "Epoch 00195: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.4821 - accuracy: 0.7869 - val_loss: 1.2099 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 196/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3847 - accuracy: 0.8000\n",
      "Epoch 00196: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4150 - accuracy: 0.7951 - val_loss: 1.2134 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 197/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.4823 - accuracy: 0.7818\n",
      "Epoch 00197: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4497 - accuracy: 0.7951 - val_loss: 1.2142 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5437 - accuracy: 0.7459\n",
      "Epoch 00198: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5437 - accuracy: 0.7459 - val_loss: 1.2151 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 199/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3938 - accuracy: 0.8273\n",
      "Epoch 00199: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4582 - accuracy: 0.7869 - val_loss: 1.2138 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 200/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3730 - accuracy: 0.8545\n",
      "Epoch 00200: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.3412 - accuracy: 0.8525 - val_loss: 1.2122 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4859 - accuracy: 0.7623\n",
      "Epoch 00201: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.4859 - accuracy: 0.7623 - val_loss: 1.2122 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 202/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.2596 - accuracy: 0.8200\n",
      "Epoch 00202: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.2666 - accuracy: 0.8361 - val_loss: 1.2135 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 203/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3133 - accuracy: 0.8000\n",
      "Epoch 00203: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.3684 - accuracy: 0.7869 - val_loss: 1.2101 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 204/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3171 - accuracy: 0.8000\n",
      "Epoch 00204: val_loss did not improve from 1.20586\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.3672 - accuracy: 0.7951 - val_loss: 1.2073 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 205/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.5399 - accuracy: 0.8000\n",
      "Epoch 00205: val_loss improved from 1.20586 to 1.20447, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.5359 - accuracy: 0.7951 - val_loss: 1.2045 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 206/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.2216 - accuracy: 0.8700\n",
      "Epoch 00206: val_loss improved from 1.20447 to 1.20053, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 1.2865 - accuracy: 0.8443 - val_loss: 1.2005 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 207/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3808 - accuracy: 0.7583\n",
      "Epoch 00207: val_loss improved from 1.20053 to 1.19945, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.3839 - accuracy: 0.7541 - val_loss: 1.1994 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 208/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.3177 - accuracy: 0.8100\n",
      "Epoch 00208: val_loss did not improve from 1.19945\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3300 - accuracy: 0.8033 - val_loss: 1.2005 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3663 - accuracy: 0.8279\n",
      "Epoch 00209: val_loss did not improve from 1.19945\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3663 - accuracy: 0.8279 - val_loss: 1.2013 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 210/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2477 - accuracy: 0.8091\n",
      "Epoch 00210: val_loss improved from 1.19945 to 1.19810, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.2407 - accuracy: 0.8033 - val_loss: 1.1981 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 211/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3129 - accuracy: 0.8167\n",
      "Epoch 00211: val_loss improved from 1.19810 to 1.19234, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.3059 - accuracy: 0.8197 - val_loss: 1.1923 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 212/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3115 - accuracy: 0.8000\n",
      "Epoch 00212: val_loss did not improve from 1.19234\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3455 - accuracy: 0.7951 - val_loss: 1.1947 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 213/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3165 - accuracy: 0.7818\n",
      "Epoch 00213: val_loss did not improve from 1.19234\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.3914 - accuracy: 0.7869 - val_loss: 1.1955 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4125 - accuracy: 0.7705\n",
      "Epoch 00214: val_loss did not improve from 1.19234\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.4125 - accuracy: 0.7705 - val_loss: 1.1993 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 215/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.3746 - accuracy: 0.7700\n",
      "Epoch 00215: val_loss did not improve from 1.19234\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.4353 - accuracy: 0.7623 - val_loss: 1.1957 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.8361\n",
      "Epoch 00216: val_loss improved from 1.19234 to 1.19130, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.3257 - accuracy: 0.8361 - val_loss: 1.1913 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3870 - accuracy: 0.7787\n",
      "Epoch 00217: val_loss did not improve from 1.19130\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.3870 - accuracy: 0.7787 - val_loss: 1.1937 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 218/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4423 - accuracy: 0.8083\n",
      "Epoch 00218: val_loss improved from 1.19130 to 1.19075, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.4372 - accuracy: 0.8115 - val_loss: 1.1908 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2452 - accuracy: 0.8279\n",
      "Epoch 00219: val_loss improved from 1.19075 to 1.18864, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.2452 - accuracy: 0.8279 - val_loss: 1.1886 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 220/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2858 - accuracy: 0.8000\n",
      "Epoch 00220: val_loss improved from 1.18864 to 1.18173, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.2786 - accuracy: 0.8033 - val_loss: 1.1817 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.7869\n",
      "Epoch 00221: val_loss improved from 1.18173 to 1.18084, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.3860 - accuracy: 0.7869 - val_loss: 1.1808 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5097 - accuracy: 0.7623\n",
      "Epoch 00222: val_loss did not improve from 1.18084\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.5097 - accuracy: 0.7623 - val_loss: 1.1850 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3978 - accuracy: 0.8115\n",
      "Epoch 00223: val_loss did not improve from 1.18084\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3978 - accuracy: 0.8115 - val_loss: 1.1815 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3993 - accuracy: 0.7541\n",
      "Epoch 00224: val_loss improved from 1.18084 to 1.18046, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.3993 - accuracy: 0.7541 - val_loss: 1.1805 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 225/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2798 - accuracy: 0.7917\n",
      "Epoch 00225: val_loss did not improve from 1.18046\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2748 - accuracy: 0.7951 - val_loss: 1.1830 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 226/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2355 - accuracy: 0.8455\n",
      "Epoch 00226: val_loss did not improve from 1.18046\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2589 - accuracy: 0.8443 - val_loss: 1.1805 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 227/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.4985 - accuracy: 0.7636\n",
      "Epoch 00227: val_loss improved from 1.18046 to 1.17709, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.4446 - accuracy: 0.7787 - val_loss: 1.1771 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3945 - accuracy: 0.7869\n",
      "Epoch 00228: val_loss improved from 1.17709 to 1.17066, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.3945 - accuracy: 0.7869 - val_loss: 1.1707 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 229/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2212 - accuracy: 0.8455\n",
      "Epoch 00229: val_loss improved from 1.17066 to 1.16619, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.3283 - accuracy: 0.8197 - val_loss: 1.1662 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 230/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3466 - accuracy: 0.7917\n",
      "Epoch 00230: val_loss did not improve from 1.16619\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3514 - accuracy: 0.7869 - val_loss: 1.1713 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 231/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2468 - accuracy: 0.8167\n",
      "Epoch 00231: val_loss did not improve from 1.16619\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2445 - accuracy: 0.8197 - val_loss: 1.1715 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 232/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2080 - accuracy: 0.8500\n",
      "Epoch 00232: val_loss did not improve from 1.16619\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2180 - accuracy: 0.8443 - val_loss: 1.1665 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 233/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.3150 - accuracy: 0.8400\n",
      "Epoch 00233: val_loss improved from 1.16619 to 1.16025, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.3011 - accuracy: 0.8525 - val_loss: 1.1603 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4505 - accuracy: 0.7623\n",
      "Epoch 00234: val_loss did not improve from 1.16025\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4505 - accuracy: 0.7623 - val_loss: 1.1614 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 235/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4688 - accuracy: 0.7667\n",
      "Epoch 00235: val_loss improved from 1.16025 to 1.15947, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.4582 - accuracy: 0.7705 - val_loss: 1.1595 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 236/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3164 - accuracy: 0.8250\n",
      "Epoch 00236: val_loss improved from 1.15947 to 1.15478, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.3340 - accuracy: 0.8115 - val_loss: 1.1548 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 237/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4652 - accuracy: 0.8083\n",
      "Epoch 00237: val_loss did not improve from 1.15478\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.5039 - accuracy: 0.8033 - val_loss: 1.1572 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 238/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3915 - accuracy: 0.8333\n",
      "Epoch 00238: val_loss improved from 1.15478 to 1.15422, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.4536 - accuracy: 0.8197 - val_loss: 1.1542 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 239/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2130 - accuracy: 0.8182\n",
      "Epoch 00239: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1761 - accuracy: 0.8361 - val_loss: 1.1548 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 240/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1790 - accuracy: 0.8667\n",
      "Epoch 00240: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2349 - accuracy: 0.8607 - val_loss: 1.1555 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 241/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.2131 - accuracy: 0.8100\n",
      "Epoch 00241: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2720 - accuracy: 0.8115 - val_loss: 1.1619 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.7623\n",
      "Epoch 00242: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.5303 - accuracy: 0.7623 - val_loss: 1.1679 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3401 - accuracy: 0.8115\n",
      "Epoch 00243: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.3401 - accuracy: 0.8115 - val_loss: 1.1715 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 244/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2347 - accuracy: 0.8750\n",
      "Epoch 00244: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2717 - accuracy: 0.8689 - val_loss: 1.1731 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2167 - accuracy: 0.8443\n",
      "Epoch 00245: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2167 - accuracy: 0.8443 - val_loss: 1.1734 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 246/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3236 - accuracy: 0.8273\n",
      "Epoch 00246: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.3119 - accuracy: 0.8279 - val_loss: 1.1701 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 247/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2952 - accuracy: 0.8417\n",
      "Epoch 00247: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.3107 - accuracy: 0.8361 - val_loss: 1.1726 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 248/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2774 - accuracy: 0.8167\n",
      "Epoch 00248: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2744 - accuracy: 0.8197 - val_loss: 1.1715 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2612 - accuracy: 0.8361\n",
      "Epoch 00249: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2612 - accuracy: 0.8361 - val_loss: 1.1709 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 250/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2232 - accuracy: 0.8182\n",
      "Epoch 00250: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2436 - accuracy: 0.8197 - val_loss: 1.1716 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 251/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.3548 - accuracy: 0.8000\n",
      "Epoch 00251: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.3497 - accuracy: 0.8033 - val_loss: 1.1699 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1914 - accuracy: 0.8525\n",
      "Epoch 00252: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1914 - accuracy: 0.8525 - val_loss: 1.1698 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3176 - accuracy: 0.8197\n",
      "Epoch 00253: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.3176 - accuracy: 0.8197 - val_loss: 1.1688 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2599 - accuracy: 0.8115\n",
      "Epoch 00254: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2599 - accuracy: 0.8115 - val_loss: 1.1674 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 255/500\n",
      " 9/13 [===================>..........] - ETA: 0s - loss: 1.2638 - accuracy: 0.8333\n",
      "Epoch 00255: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.2784 - accuracy: 0.8197 - val_loss: 1.1666 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 256/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1860 - accuracy: 0.8727\n",
      "Epoch 00256: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1944 - accuracy: 0.8607 - val_loss: 1.1635 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 257/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3601 - accuracy: 0.8500\n",
      "Epoch 00257: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.3511 - accuracy: 0.8525 - val_loss: 1.1626 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 258/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2476 - accuracy: 0.7917\n",
      "Epoch 00258: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2404 - accuracy: 0.7951 - val_loss: 1.1649 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 259/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1887 - accuracy: 0.8182\n",
      "Epoch 00259: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2712 - accuracy: 0.8115 - val_loss: 1.1643 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 260/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2486 - accuracy: 0.8583\n",
      "Epoch 00260: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2680 - accuracy: 0.8525 - val_loss: 1.1619 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 261/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1830 - accuracy: 0.8455\n",
      "Epoch 00261: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1503 - accuracy: 0.8607 - val_loss: 1.1616 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 262/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2751 - accuracy: 0.8250\n",
      "Epoch 00262: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2902 - accuracy: 0.8115 - val_loss: 1.1614 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 263/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1828 - accuracy: 0.8167\n",
      "Epoch 00263: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2150 - accuracy: 0.8033 - val_loss: 1.1625 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2258 - accuracy: 0.8279\n",
      "Epoch 00264: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2258 - accuracy: 0.8279 - val_loss: 1.1617 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 265/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2285 - accuracy: 0.8250\n",
      "Epoch 00265: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2928 - accuracy: 0.8115 - val_loss: 1.1592 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 266/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1199 - accuracy: 0.8750\n",
      "Epoch 00266: val_loss did not improve from 1.15422\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1161 - accuracy: 0.8770 - val_loss: 1.1547 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 267/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.2721 - accuracy: 0.8364\n",
      "Epoch 00267: val_loss improved from 1.15422 to 1.15217, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.2715 - accuracy: 0.8361 - val_loss: 1.1522 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3157 - accuracy: 0.7869\n",
      "Epoch 00268: val_loss improved from 1.15217 to 1.15151, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.3157 - accuracy: 0.7869 - val_loss: 1.1515 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 269/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2092 - accuracy: 0.8000\n",
      "Epoch 00269: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2300 - accuracy: 0.7951 - val_loss: 1.1539 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 270/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2129 - accuracy: 0.8583\n",
      "Epoch 00270: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2111 - accuracy: 0.8607 - val_loss: 1.1558 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 271/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1221 - accuracy: 0.8800\n",
      "Epoch 00271: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1076 - accuracy: 0.8770 - val_loss: 1.1527 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 272/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1113 - accuracy: 0.8917\n",
      "Epoch 00272: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1878 - accuracy: 0.8852 - val_loss: 1.1555 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1948 - accuracy: 0.8607\n",
      "Epoch 00273: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.1948 - accuracy: 0.8607 - val_loss: 1.1592 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 274/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2795 - accuracy: 0.8250\n",
      "Epoch 00274: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2729 - accuracy: 0.8279 - val_loss: 1.1556 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 275/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.5012 - accuracy: 0.7833\n",
      "Epoch 00275: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.5333 - accuracy: 0.7787 - val_loss: 1.1527 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2932 - accuracy: 0.8525\n",
      "Epoch 00276: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.2932 - accuracy: 0.8525 - val_loss: 1.1559 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1838 - accuracy: 0.8607\n",
      "Epoch 00277: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.1838 - accuracy: 0.8607 - val_loss: 1.1561 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 278/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1456 - accuracy: 0.8364\n",
      "Epoch 00278: val_loss did not improve from 1.15151\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.2366 - accuracy: 0.8197 - val_loss: 1.1552 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1532 - accuracy: 0.8361\n",
      "Epoch 00279: val_loss improved from 1.15151 to 1.14643, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1532 - accuracy: 0.8361 - val_loss: 1.1464 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 280/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2897 - accuracy: 0.8167\n",
      "Epoch 00280: val_loss improved from 1.14643 to 1.14441, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2821 - accuracy: 0.8197 - val_loss: 1.1444 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 281/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2269 - accuracy: 0.8750\n",
      "Epoch 00281: val_loss improved from 1.14441 to 1.14438, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.2311 - accuracy: 0.8689 - val_loss: 1.1444 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 282/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1827 - accuracy: 0.8417\n",
      "Epoch 00282: val_loss improved from 1.14438 to 1.14432, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1865 - accuracy: 0.8361 - val_loss: 1.1443 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2572 - accuracy: 0.8525\n",
      "Epoch 00283: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2572 - accuracy: 0.8525 - val_loss: 1.1466 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 284/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1074 - accuracy: 0.8667\n",
      "Epoch 00284: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1346 - accuracy: 0.8525 - val_loss: 1.1462 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 285/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2686 - accuracy: 0.8083\n",
      "Epoch 00285: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2699 - accuracy: 0.8033 - val_loss: 1.1490 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1448 - accuracy: 0.8525\n",
      "Epoch 00286: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1448 - accuracy: 0.8525 - val_loss: 1.1480 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1871 - accuracy: 0.8607\n",
      "Epoch 00287: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1871 - accuracy: 0.8607 - val_loss: 1.1479 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 288/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1511 - accuracy: 0.8750\n",
      "Epoch 00288: val_loss did not improve from 1.14432\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1552 - accuracy: 0.8689 - val_loss: 1.1457 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 289/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2002 - accuracy: 0.8000\n",
      "Epoch 00289: val_loss improved from 1.14432 to 1.14416, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2211 - accuracy: 0.7951 - val_loss: 1.1442 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2292 - accuracy: 0.8525\n",
      "Epoch 00290: val_loss did not improve from 1.14416\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2292 - accuracy: 0.8525 - val_loss: 1.1464 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 291/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9894 - accuracy: 0.9333\n",
      "Epoch 00291: val_loss improved from 1.14416 to 1.14398, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9998 - accuracy: 0.9262 - val_loss: 1.1440 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1829 - accuracy: 0.8689\n",
      "Epoch 00292: val_loss improved from 1.14398 to 1.14107, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.1829 - accuracy: 0.8689 - val_loss: 1.1411 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 293/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1612 - accuracy: 0.8455\n",
      "Epoch 00293: val_loss improved from 1.14107 to 1.13760, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1534 - accuracy: 0.8443 - val_loss: 1.1376 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 294/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2698 - accuracy: 0.8083\n",
      "Epoch 00294: val_loss did not improve from 1.13760\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2623 - accuracy: 0.8115 - val_loss: 1.1386 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 295/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1015 - accuracy: 0.9000\n",
      "Epoch 00295: val_loss improved from 1.13760 to 1.13644, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1304 - accuracy: 0.8770 - val_loss: 1.1364 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 296/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2947 - accuracy: 0.8000\n",
      "Epoch 00296: val_loss did not improve from 1.13644\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2933 - accuracy: 0.7951 - val_loss: 1.1372 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 297/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1819 - accuracy: 0.8364\n",
      "Epoch 00297: val_loss did not improve from 1.13644\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1919 - accuracy: 0.8361 - val_loss: 1.1398 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 298/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1890 - accuracy: 0.8667\n",
      "Epoch 00298: val_loss improved from 1.13644 to 1.13500, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.2137 - accuracy: 0.8607 - val_loss: 1.1350 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 299/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0322 - accuracy: 0.8727\n",
      "Epoch 00299: val_loss improved from 1.13500 to 1.13203, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0260 - accuracy: 0.8770 - val_loss: 1.1320 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2243 - accuracy: 0.7951\n",
      "Epoch 00300: val_loss improved from 1.13203 to 1.12984, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.2243 - accuracy: 0.7951 - val_loss: 1.1298 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 301/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3096 - accuracy: 0.7727\n",
      "Epoch 00301: val_loss improved from 1.12984 to 1.12551, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.3673 - accuracy: 0.7377 - val_loss: 1.1255 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2239 - accuracy: 0.8361\n",
      "Epoch 00302: val_loss improved from 1.12551 to 1.11965, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.2239 - accuracy: 0.8361 - val_loss: 1.1197 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 303/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1194 - accuracy: 0.8750\n",
      "Epoch 00303: val_loss improved from 1.11965 to 1.11314, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.1876 - accuracy: 0.8607 - val_loss: 1.1131 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1416 - accuracy: 0.8689\n",
      "Epoch 00304: val_loss improved from 1.11314 to 1.10517, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1416 - accuracy: 0.8689 - val_loss: 1.1052 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 305/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1652 - accuracy: 0.8333\n",
      "Epoch 00305: val_loss improved from 1.10517 to 1.09999, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1611 - accuracy: 0.8361 - val_loss: 1.1000 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 306/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.3384 - accuracy: 0.8182\n",
      "Epoch 00306: val_loss improved from 1.09999 to 1.09915, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.2947 - accuracy: 0.8279 - val_loss: 1.0991 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 307/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1457 - accuracy: 0.8400\n",
      "Epoch 00307: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1380 - accuracy: 0.8361 - val_loss: 1.1020 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1966 - accuracy: 0.8525\n",
      "Epoch 00308: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1966 - accuracy: 0.8525 - val_loss: 1.1022 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 309/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3329 - accuracy: 0.8000\n",
      "Epoch 00309: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.4105 - accuracy: 0.7869 - val_loss: 1.1049 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 310/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1548 - accuracy: 0.8417\n",
      "Epoch 00310: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2065 - accuracy: 0.8279 - val_loss: 1.1077 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 311/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2222 - accuracy: 0.8333\n",
      "Epoch 00311: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2162 - accuracy: 0.8361 - val_loss: 1.1076 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 312/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1313 - accuracy: 0.8545\n",
      "Epoch 00312: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1150 - accuracy: 0.8607 - val_loss: 1.1065 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 313/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1512 - accuracy: 0.8600\n",
      "Epoch 00313: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.1363 - accuracy: 0.8607 - val_loss: 1.1034 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 314/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.3505 - accuracy: 0.7917\n",
      "Epoch 00314: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.3497 - accuracy: 0.7869 - val_loss: 1.1001 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 315/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0730 - accuracy: 0.8917\n",
      "Epoch 00315: val_loss did not improve from 1.09915\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0710 - accuracy: 0.8934 - val_loss: 1.0994 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 316/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0646 - accuracy: 0.8917\n",
      "Epoch 00316: val_loss improved from 1.09915 to 1.09871, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1181 - accuracy: 0.8852 - val_loss: 1.0987 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 317/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0768 - accuracy: 0.9000\n",
      "Epoch 00317: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1504 - accuracy: 0.8852 - val_loss: 1.1026 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1946 - accuracy: 0.7869\n",
      "Epoch 00318: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1946 - accuracy: 0.7869 - val_loss: 1.1061 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.8525\n",
      "Epoch 00319: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1788 - accuracy: 0.8525 - val_loss: 1.1070 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 320/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2044 - accuracy: 0.8417\n",
      "Epoch 00320: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2019 - accuracy: 0.8443 - val_loss: 1.1091 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 321/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0833 - accuracy: 0.8917\n",
      "Epoch 00321: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1099 - accuracy: 0.8852 - val_loss: 1.1092 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2713 - accuracy: 0.8197\n",
      "Epoch 00322: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2713 - accuracy: 0.8197 - val_loss: 1.1102 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.8852\n",
      "Epoch 00323: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.0600 - accuracy: 0.8852 - val_loss: 1.1106 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 324/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1787 - accuracy: 0.8583\n",
      "Epoch 00324: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1726 - accuracy: 0.8607 - val_loss: 1.1094 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1373 - accuracy: 0.8689\n",
      "Epoch 00325: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.1373 - accuracy: 0.8689 - val_loss: 1.1084 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 326/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1438 - accuracy: 0.9000\n",
      "Epoch 00326: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1208 - accuracy: 0.9098 - val_loss: 1.1084 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 327/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1760 - accuracy: 0.8545\n",
      "Epoch 00327: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.2154 - accuracy: 0.8361 - val_loss: 1.1097 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1492 - accuracy: 0.8361\n",
      "Epoch 00328: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1492 - accuracy: 0.8361 - val_loss: 1.1104 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 329/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9915 - accuracy: 0.9455\n",
      "Epoch 00329: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0170 - accuracy: 0.9344 - val_loss: 1.1070 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1777 - accuracy: 0.8525\n",
      "Epoch 00330: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1777 - accuracy: 0.8525 - val_loss: 1.1054 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2556 - accuracy: 0.8443\n",
      "Epoch 00331: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.2556 - accuracy: 0.8443 - val_loss: 1.1051 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 332/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1311 - accuracy: 0.8583\n",
      "Epoch 00332: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1607 - accuracy: 0.8525 - val_loss: 1.1007 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 333/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2219 - accuracy: 0.8917\n",
      "Epoch 00333: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2218 - accuracy: 0.8852 - val_loss: 1.1022 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 334/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1433 - accuracy: 0.8500\n",
      "Epoch 00334: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1433 - accuracy: 0.8525 - val_loss: 1.1032 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 335/500\n",
      " 9/13 [===================>..........] - ETA: 0s - loss: 0.9929 - accuracy: 0.9111\n",
      "Epoch 00335: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.9702 - accuracy: 0.9180 - val_loss: 1.1047 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1807 - accuracy: 0.8770\n",
      "Epoch 00336: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1807 - accuracy: 0.8770 - val_loss: 1.1044 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 337/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1645 - accuracy: 0.8727\n",
      "Epoch 00337: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.2272 - accuracy: 0.8443 - val_loss: 1.1036 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 338/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1116 - accuracy: 0.8636\n",
      "Epoch 00338: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.1300 - accuracy: 0.8525 - val_loss: 1.1015 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 339/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1013 - accuracy: 0.8583\n",
      "Epoch 00339: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.0968 - accuracy: 0.8607 - val_loss: 1.1010 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 340/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1854 - accuracy: 0.8417\n",
      "Epoch 00340: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1788 - accuracy: 0.8443 - val_loss: 1.1038 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 341/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1369 - accuracy: 0.8500\n",
      "Epoch 00341: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1607 - accuracy: 0.8361 - val_loss: 1.1039 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 342/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0808 - accuracy: 0.8727\n",
      "Epoch 00342: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1509 - accuracy: 0.8525 - val_loss: 1.1069 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 343/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1099 - accuracy: 0.9000\n",
      "Epoch 00343: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.1317 - accuracy: 0.8934 - val_loss: 1.1047 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0539 - accuracy: 0.9016\n",
      "Epoch 00344: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0539 - accuracy: 0.9016 - val_loss: 1.1023 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 345/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0974 - accuracy: 0.8750\n",
      "Epoch 00345: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1332 - accuracy: 0.8689 - val_loss: 1.1017 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1930 - accuracy: 0.8525\n",
      "Epoch 00346: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1930 - accuracy: 0.8525 - val_loss: 1.1074 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 347/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0545 - accuracy: 0.8545\n",
      "Epoch 00347: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0573 - accuracy: 0.8525 - val_loss: 1.1057 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 348/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0379 - accuracy: 0.8727\n",
      "Epoch 00348: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0747 - accuracy: 0.8607 - val_loss: 1.1025 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 349/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0627 - accuracy: 0.9083\n",
      "Epoch 00349: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0750 - accuracy: 0.9016 - val_loss: 1.1016 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1413 - accuracy: 0.8689\n",
      "Epoch 00350: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1413 - accuracy: 0.8689 - val_loss: 1.1046 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.8607\n",
      "Epoch 00351: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0350 - accuracy: 0.8607 - val_loss: 1.1036 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 352/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1088 - accuracy: 0.8364\n",
      "Epoch 00352: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1133 - accuracy: 0.8443 - val_loss: 1.1008 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 353/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1061 - accuracy: 0.8833\n",
      "Epoch 00353: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1022 - accuracy: 0.8852 - val_loss: 1.1013 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 354/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1484 - accuracy: 0.8417\n",
      "Epoch 00354: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1488 - accuracy: 0.8443 - val_loss: 1.1014 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 355/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9853 - accuracy: 0.9167\n",
      "Epoch 00355: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9819 - accuracy: 0.9180 - val_loss: 1.1017 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 356/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9534 - accuracy: 0.9273\n",
      "Epoch 00356: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9425 - accuracy: 0.9344 - val_loss: 1.1012 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 357/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1486 - accuracy: 0.8636\n",
      "Epoch 00357: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.1393 - accuracy: 0.8689 - val_loss: 1.0989 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 358/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9982 - accuracy: 0.9167\n",
      "Epoch 00358: val_loss did not improve from 1.09871\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.0129 - accuracy: 0.9098 - val_loss: 1.0988 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 359/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2072 - accuracy: 0.8167\n",
      "Epoch 00359: val_loss improved from 1.09871 to 1.09726, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.2002 - accuracy: 0.8197 - val_loss: 1.0973 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 360/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1044 - accuracy: 0.8545\n",
      "Epoch 00360: val_loss improved from 1.09726 to 1.09063, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1150 - accuracy: 0.8443 - val_loss: 1.0906 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 361/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2481 - accuracy: 0.8167\n",
      "Epoch 00361: val_loss improved from 1.09063 to 1.08723, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.2410 - accuracy: 0.8197 - val_loss: 1.0872 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 362/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0342 - accuracy: 0.9000\n",
      "Epoch 00362: val_loss improved from 1.08723 to 1.08445, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.0354 - accuracy: 0.8934 - val_loss: 1.0845 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 363/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1152 - accuracy: 0.8455\n",
      "Epoch 00363: val_loss improved from 1.08445 to 1.08199, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1102 - accuracy: 0.8525 - val_loss: 1.0820 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 364/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0219 - accuracy: 0.9000\n",
      "Epoch 00364: val_loss improved from 1.08199 to 1.08067, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.0871 - accuracy: 0.8934 - val_loss: 1.0807 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 365/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0741 - accuracy: 0.8455\n",
      "Epoch 00365: val_loss improved from 1.08067 to 1.07962, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0930 - accuracy: 0.8361 - val_loss: 1.0796 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 366/500\n",
      " 9/13 [===================>..........] - ETA: 0s - loss: 1.0681 - accuracy: 0.8667\n",
      "Epoch 00366: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0741 - accuracy: 0.8689 - val_loss: 1.0800 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 367/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.0044 - accuracy: 0.9000\n",
      "Epoch 00367: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0064 - accuracy: 0.9098 - val_loss: 1.0808 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 368/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1101 - accuracy: 0.8583\n",
      "Epoch 00368: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1204 - accuracy: 0.8525 - val_loss: 1.0824 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 369/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.0965 - accuracy: 0.8800\n",
      "Epoch 00369: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0937 - accuracy: 0.8852 - val_loss: 1.0821 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 370/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.2349 - accuracy: 0.8000\n",
      "Epoch 00370: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2089 - accuracy: 0.8033 - val_loss: 1.0813 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 371/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 0.9805 - accuracy: 0.9000\n",
      "Epoch 00371: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.9821 - accuracy: 0.8934 - val_loss: 1.0826 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.8525\n",
      "Epoch 00372: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1565 - accuracy: 0.8525 - val_loss: 1.0810 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 373/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0803 - accuracy: 0.9000\n",
      "Epoch 00373: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1220 - accuracy: 0.8852 - val_loss: 1.0799 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1413 - accuracy: 0.8525\n",
      "Epoch 00374: val_loss did not improve from 1.07962\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1413 - accuracy: 0.8525 - val_loss: 1.0806 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0901 - accuracy: 0.8689\n",
      "Epoch 00375: val_loss improved from 1.07962 to 1.07732, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.0901 - accuracy: 0.8689 - val_loss: 1.0773 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 376/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9986 - accuracy: 0.8750\n",
      "Epoch 00376: val_loss improved from 1.07732 to 1.07655, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9950 - accuracy: 0.8770 - val_loss: 1.0766 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1390 - accuracy: 0.8607\n",
      "Epoch 00377: val_loss improved from 1.07655 to 1.07614, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1390 - accuracy: 0.8607 - val_loss: 1.0761 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0594 - accuracy: 0.8934\n",
      "Epoch 00378: val_loss did not improve from 1.07614\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0594 - accuracy: 0.8934 - val_loss: 1.0768 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 379/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1690 - accuracy: 0.8455\n",
      "Epoch 00379: val_loss improved from 1.07614 to 1.07452, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1470 - accuracy: 0.8525 - val_loss: 1.0745 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.8934\n",
      "Epoch 00380: val_loss improved from 1.07452 to 1.07063, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0783 - accuracy: 0.8934 - val_loss: 1.0706 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1392 - accuracy: 0.8361\n",
      "Epoch 00381: val_loss improved from 1.07063 to 1.06934, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.1392 - accuracy: 0.8361 - val_loss: 1.0693 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 382/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.1151 - accuracy: 0.8273\n",
      "Epoch 00382: val_loss improved from 1.06934 to 1.06762, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1491 - accuracy: 0.8033 - val_loss: 1.0676 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0715 - accuracy: 0.8525\n",
      "Epoch 00383: val_loss improved from 1.06762 to 1.06718, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.0715 - accuracy: 0.8525 - val_loss: 1.0672 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1967 - accuracy: 0.8361\n",
      "Epoch 00384: val_loss improved from 1.06718 to 1.06374, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.1967 - accuracy: 0.8361 - val_loss: 1.0637 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0635 - accuracy: 0.8607\n",
      "Epoch 00385: val_loss did not improve from 1.06374\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0635 - accuracy: 0.8607 - val_loss: 1.0642 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 386/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.1714 - accuracy: 0.8500\n",
      "Epoch 00386: val_loss improved from 1.06374 to 1.06353, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 1.2008 - accuracy: 0.8607 - val_loss: 1.0635 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 387/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1505 - accuracy: 0.8417\n",
      "Epoch 00387: val_loss did not improve from 1.06353\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1440 - accuracy: 0.8443 - val_loss: 1.0654 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 388/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1072 - accuracy: 0.8417\n",
      "Epoch 00388: val_loss did not improve from 1.06353\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.1539 - accuracy: 0.8279 - val_loss: 1.0680 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 389/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.2364 - accuracy: 0.7833\n",
      "Epoch 00389: val_loss did not improve from 1.06353\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.2349 - accuracy: 0.7869 - val_loss: 1.0685 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0624 - accuracy: 0.8852\n",
      "Epoch 00390: val_loss did not improve from 1.06353\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0624 - accuracy: 0.8852 - val_loss: 1.0657 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 391/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1484 - accuracy: 0.8167\n",
      "Epoch 00391: val_loss improved from 1.06353 to 1.06310, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1423 - accuracy: 0.8197 - val_loss: 1.0631 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 392/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9889 - accuracy: 0.8750\n",
      "Epoch 00392: val_loss improved from 1.06310 to 1.06301, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9886 - accuracy: 0.8770 - val_loss: 1.0630 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1491 - accuracy: 0.8115\n",
      "Epoch 00393: val_loss did not improve from 1.06301\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.1491 - accuracy: 0.8115 - val_loss: 1.0634 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.9016\n",
      "Epoch 00394: val_loss did not improve from 1.06301\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9709 - accuracy: 0.9016 - val_loss: 1.0656 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 395/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1364 - accuracy: 0.8417\n",
      "Epoch 00395: val_loss did not improve from 1.06301\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1612 - accuracy: 0.8361 - val_loss: 1.0658 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 396/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0304 - accuracy: 0.8917\n",
      "Epoch 00396: val_loss did not improve from 1.06301\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0297 - accuracy: 0.8934 - val_loss: 1.0634 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.8689\n",
      "Epoch 00397: val_loss improved from 1.06301 to 1.06060, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.0095 - accuracy: 0.8689 - val_loss: 1.0606 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 398/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0285 - accuracy: 0.8727\n",
      "Epoch 00398: val_loss did not improve from 1.06060\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1061 - accuracy: 0.8525 - val_loss: 1.0631 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 399/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9770 - accuracy: 0.9333\n",
      "Epoch 00399: val_loss did not improve from 1.06060\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9833 - accuracy: 0.9262 - val_loss: 1.0654 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 400/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0233 - accuracy: 0.9250\n",
      "Epoch 00400: val_loss did not improve from 1.06060\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0189 - accuracy: 0.9262 - val_loss: 1.0669 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 401/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1296 - accuracy: 0.8833\n",
      "Epoch 00401: val_loss did not improve from 1.06060\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1634 - accuracy: 0.8689 - val_loss: 1.0655 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0618 - accuracy: 0.8770\n",
      "Epoch 00402: val_loss did not improve from 1.06060\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0618 - accuracy: 0.8770 - val_loss: 1.0614 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.9180\n",
      "Epoch 00403: val_loss improved from 1.06060 to 1.05846, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9714 - accuracy: 0.9180 - val_loss: 1.0585 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 404/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0282 - accuracy: 0.8583\n",
      "Epoch 00404: val_loss did not improve from 1.05846\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0369 - accuracy: 0.8525 - val_loss: 1.0586 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.9590\n",
      "Epoch 00405: val_loss did not improve from 1.05846\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9219 - accuracy: 0.9590 - val_loss: 1.0604 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 406/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0575 - accuracy: 0.8833\n",
      "Epoch 00406: val_loss did not improve from 1.05846\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0528 - accuracy: 0.8852 - val_loss: 1.0588 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1324 - accuracy: 0.8525\n",
      "Epoch 00407: val_loss improved from 1.05846 to 1.05811, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1324 - accuracy: 0.8525 - val_loss: 1.0581 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9310 - accuracy: 0.9508\n",
      "Epoch 00408: val_loss did not improve from 1.05811\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9310 - accuracy: 0.9508 - val_loss: 1.0582 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 409/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1412 - accuracy: 0.8667\n",
      "Epoch 00409: val_loss did not improve from 1.05811\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1514 - accuracy: 0.8607 - val_loss: 1.0586 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1229 - accuracy: 0.8115\n",
      "Epoch 00410: val_loss improved from 1.05811 to 1.05618, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1229 - accuracy: 0.8115 - val_loss: 1.0562 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 411/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9155 - accuracy: 0.9417\n",
      "Epoch 00411: val_loss improved from 1.05618 to 1.05331, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9170 - accuracy: 0.9426 - val_loss: 1.0533 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 412/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1503 - accuracy: 0.8667\n",
      "Epoch 00412: val_loss improved from 1.05331 to 1.05313, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1.1703 - accuracy: 0.8607 - val_loss: 1.0531 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 413/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0129 - accuracy: 0.9000\n",
      "Epoch 00413: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0415 - accuracy: 0.8934 - val_loss: 1.0582 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 414/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0541 - accuracy: 0.9083\n",
      "Epoch 00414: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0655 - accuracy: 0.9016 - val_loss: 1.0604 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 415/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0015 - accuracy: 0.8500\n",
      "Epoch 00415: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0167 - accuracy: 0.8361 - val_loss: 1.0617 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.9262\n",
      "Epoch 00416: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9829 - accuracy: 0.9262 - val_loss: 1.0612 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.8607\n",
      "Epoch 00417: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0860 - accuracy: 0.8607 - val_loss: 1.0619 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 418/500\n",
      " 9/13 [===================>..........] - ETA: 0s - loss: 0.9796 - accuracy: 0.8889\n",
      "Epoch 00418: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1.0142 - accuracy: 0.8689 - val_loss: 1.0599 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9787 - accuracy: 0.9098\n",
      "Epoch 00419: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.9787 - accuracy: 0.9098 - val_loss: 1.0580 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0915 - accuracy: 0.8852\n",
      "Epoch 00420: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0915 - accuracy: 0.8852 - val_loss: 1.0601 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 421/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0459 - accuracy: 0.9167\n",
      "Epoch 00421: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0415 - accuracy: 0.9180 - val_loss: 1.0577 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0075 - accuracy: 0.9180\n",
      "Epoch 00422: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.0075 - accuracy: 0.9180 - val_loss: 1.0586 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9600 - accuracy: 0.9098\n",
      "Epoch 00423: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9600 - accuracy: 0.9098 - val_loss: 1.0579 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0473 - accuracy: 0.8607\n",
      "Epoch 00424: val_loss did not improve from 1.05313\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.0473 - accuracy: 0.8607 - val_loss: 1.0554 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 425/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0256 - accuracy: 0.8750\n",
      "Epoch 00425: val_loss improved from 1.05313 to 1.05249, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0437 - accuracy: 0.8689 - val_loss: 1.0525 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 426/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1190 - accuracy: 0.8167\n",
      "Epoch 00426: val_loss improved from 1.05249 to 1.05213, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.1174 - accuracy: 0.8197 - val_loss: 1.0521 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 427/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1260 - accuracy: 0.8417\n",
      "Epoch 00427: val_loss improved from 1.05213 to 1.05113, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.1278 - accuracy: 0.8361 - val_loss: 1.0511 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 428/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0719 - accuracy: 0.8917\n",
      "Epoch 00428: val_loss improved from 1.05113 to 1.05050, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.0705 - accuracy: 0.8934 - val_loss: 1.0505 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 429/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9241 - accuracy: 0.9250\n",
      "Epoch 00429: val_loss improved from 1.05050 to 1.05022, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9632 - accuracy: 0.9098 - val_loss: 1.0502 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0010 - accuracy: 0.8934\n",
      "Epoch 00430: val_loss improved from 1.05022 to 1.04992, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0010 - accuracy: 0.8934 - val_loss: 1.0499 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 431/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9966 - accuracy: 0.9000\n",
      "Epoch 00431: val_loss improved from 1.04992 to 1.04889, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9874 - accuracy: 0.9016 - val_loss: 1.0489 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.8934\n",
      "Epoch 00432: val_loss did not improve from 1.04889\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9695 - accuracy: 0.8934 - val_loss: 1.0506 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 433/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9873 - accuracy: 0.9000\n",
      "Epoch 00433: val_loss improved from 1.04889 to 1.04671, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.9969 - accuracy: 0.9016 - val_loss: 1.0467 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 434/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0448 - accuracy: 0.8545\n",
      "Epoch 00434: val_loss improved from 1.04671 to 1.04495, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0391 - accuracy: 0.8525 - val_loss: 1.0450 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 435/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9649 - accuracy: 0.9000\n",
      "Epoch 00435: val_loss improved from 1.04495 to 1.04404, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9910 - accuracy: 0.8852 - val_loss: 1.0440 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 436/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0227 - accuracy: 0.8636\n",
      "Epoch 00436: val_loss improved from 1.04404 to 1.04333, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0143 - accuracy: 0.8607 - val_loss: 1.0433 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 437/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 0.9775 - accuracy: 0.8900\n",
      "Epoch 00437: val_loss improved from 1.04333 to 1.04093, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.0731 - accuracy: 0.8852 - val_loss: 1.0409 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 438/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9603 - accuracy: 0.9250\n",
      "Epoch 00438: val_loss improved from 1.04093 to 1.03897, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.9651 - accuracy: 0.9180 - val_loss: 1.0390 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 439/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9075 - accuracy: 0.9417\n",
      "Epoch 00439: val_loss improved from 1.03897 to 1.03651, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9050 - accuracy: 0.9426 - val_loss: 1.0365 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 440/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.8916 - accuracy: 0.9273\n",
      "Epoch 00440: val_loss improved from 1.03651 to 1.03366, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9013 - accuracy: 0.9180 - val_loss: 1.0337 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9284 - accuracy: 0.9508\n",
      "Epoch 00441: val_loss improved from 1.03366 to 1.03264, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9284 - accuracy: 0.9508 - val_loss: 1.0326 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9138 - accuracy: 0.9590\n",
      "Epoch 00442: val_loss improved from 1.03264 to 1.03167, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9138 - accuracy: 0.9590 - val_loss: 1.0317 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0367 - accuracy: 0.8852\n",
      "Epoch 00443: val_loss improved from 1.03167 to 1.02981, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1.0367 - accuracy: 0.8852 - val_loss: 1.0298 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 444/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0775 - accuracy: 0.8818\n",
      "Epoch 00444: val_loss improved from 1.02981 to 1.02901, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.1588 - accuracy: 0.8607 - val_loss: 1.0290 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 445/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9849 - accuracy: 0.8917\n",
      "Epoch 00445: val_loss improved from 1.02901 to 1.02449, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9898 - accuracy: 0.8852 - val_loss: 1.0245 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 446/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9368 - accuracy: 0.9000\n",
      "Epoch 00446: val_loss did not improve from 1.02449\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9686 - accuracy: 0.8770 - val_loss: 1.0250 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 447/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 0.9957 - accuracy: 0.9100\n",
      "Epoch 00447: val_loss improved from 1.02449 to 1.02395, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.9904 - accuracy: 0.9098 - val_loss: 1.0239 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 448/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.0274 - accuracy: 0.8600\n",
      "Epoch 00448: val_loss did not improve from 1.02395\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.0119 - accuracy: 0.8689 - val_loss: 1.0244 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 449/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0292 - accuracy: 0.8917\n",
      "Epoch 00449: val_loss improved from 1.02395 to 1.02103, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0253 - accuracy: 0.8934 - val_loss: 1.0210 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 450/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9829 - accuracy: 0.8909\n",
      "Epoch 00450: val_loss improved from 1.02103 to 1.01966, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.0072 - accuracy: 0.8852 - val_loss: 1.0197 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9697 - accuracy: 0.8852\n",
      "Epoch 00451: val_loss improved from 1.01966 to 1.01807, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9697 - accuracy: 0.8852 - val_loss: 1.0181 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9918 - accuracy: 0.9016\n",
      "Epoch 00452: val_loss improved from 1.01807 to 1.01544, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.9918 - accuracy: 0.9016 - val_loss: 1.0154 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 453/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0275 - accuracy: 0.8667\n",
      "Epoch 00453: val_loss improved from 1.01544 to 1.01144, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0281 - accuracy: 0.8689 - val_loss: 1.0114 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 454/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9368 - accuracy: 0.9182\n",
      "Epoch 00454: val_loss improved from 1.01144 to 1.00835, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0043 - accuracy: 0.9180 - val_loss: 1.0084 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 455/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 0.9990 - accuracy: 0.8600\n",
      "Epoch 00455: val_loss improved from 1.00835 to 1.00665, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.9666 - accuracy: 0.8852 - val_loss: 1.0067 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 456/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.1455 - accuracy: 0.8583\n",
      "Epoch 00456: val_loss did not improve from 1.00665\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.1396 - accuracy: 0.8607 - val_loss: 1.0071 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 457/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.8886 - accuracy: 0.9273\n",
      "Epoch 00457: val_loss did not improve from 1.00665\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8873 - accuracy: 0.9262 - val_loss: 1.0068 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 458/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9899 - accuracy: 0.9083\n",
      "Epoch 00458: val_loss improved from 1.00665 to 1.00565, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.9901 - accuracy: 0.9098 - val_loss: 1.0056 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 459/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9249 - accuracy: 0.9083\n",
      "Epoch 00459: val_loss did not improve from 1.00565\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9244 - accuracy: 0.9098 - val_loss: 1.0064 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 460/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9471 - accuracy: 0.9083\n",
      "Epoch 00460: val_loss improved from 1.00565 to 1.00532, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.9434 - accuracy: 0.9098 - val_loss: 1.0053 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.9344\n",
      "Epoch 00461: val_loss improved from 1.00532 to 1.00436, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.9057 - accuracy: 0.9344 - val_loss: 1.0044 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 462/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 0.9212 - accuracy: 0.9300\n",
      "Epoch 00462: val_loss improved from 1.00436 to 1.00142, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9023 - accuracy: 0.9344 - val_loss: 1.0014 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 463/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.0111 - accuracy: 0.9083\n",
      "Epoch 00463: val_loss improved from 1.00142 to 1.00023, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.0073 - accuracy: 0.9098 - val_loss: 1.0002 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0424 - accuracy: 0.8689\n",
      "Epoch 00464: val_loss improved from 1.00023 to 0.99837, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0424 - accuracy: 0.8689 - val_loss: 0.9984 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.8852\n",
      "Epoch 00465: val_loss improved from 0.99837 to 0.99560, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1.0317 - accuracy: 0.8852 - val_loss: 0.9956 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 466/500\n",
      " 9/13 [===================>..........] - ETA: 0s - loss: 0.9455 - accuracy: 0.9000\n",
      "Epoch 00466: val_loss improved from 0.99560 to 0.99496, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9439 - accuracy: 0.9016 - val_loss: 0.9950 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 467/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9361 - accuracy: 0.9333\n",
      "Epoch 00467: val_loss did not improve from 0.99496\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9332 - accuracy: 0.9344 - val_loss: 0.9950 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0030 - accuracy: 0.8852\n",
      "Epoch 00468: val_loss improved from 0.99496 to 0.99326, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1.0030 - accuracy: 0.8852 - val_loss: 0.9933 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.9180\n",
      "Epoch 00469: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1.0088 - accuracy: 0.9180 - val_loss: 0.9933 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9500 - accuracy: 0.8934\n",
      "Epoch 00470: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.9500 - accuracy: 0.8934 - val_loss: 0.9995 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 471/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9398 - accuracy: 0.9333\n",
      "Epoch 00471: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9592 - accuracy: 0.9262 - val_loss: 1.0023 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 472/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9031 - accuracy: 0.9455\n",
      "Epoch 00472: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.8919 - accuracy: 0.9508 - val_loss: 1.0036 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0659 - accuracy: 0.8934\n",
      "Epoch 00473: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0659 - accuracy: 0.8934 - val_loss: 1.0043 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 474/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0394 - accuracy: 0.8909\n",
      "Epoch 00474: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0246 - accuracy: 0.8934 - val_loss: 1.0038 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 475/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9805 - accuracy: 0.9273\n",
      "Epoch 00475: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.9957 - accuracy: 0.9098 - val_loss: 1.0054 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 476/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9214 - accuracy: 0.9167\n",
      "Epoch 00476: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9486 - accuracy: 0.9098 - val_loss: 1.0040 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.8770\n",
      "Epoch 00477: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.0270 - accuracy: 0.8770 - val_loss: 0.9987 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.9016\n",
      "Epoch 00478: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.0292 - accuracy: 0.9016 - val_loss: 0.9987 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1084 - accuracy: 0.9180\n",
      "Epoch 00479: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.1084 - accuracy: 0.9180 - val_loss: 1.0009 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 480/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8944 - accuracy: 0.9083\n",
      "Epoch 00480: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8926 - accuracy: 0.9098 - val_loss: 0.9994 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9081 - accuracy: 0.9098\n",
      "Epoch 00481: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9081 - accuracy: 0.9098 - val_loss: 0.9954 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9123 - accuracy: 0.9180\n",
      "Epoch 00482: val_loss did not improve from 0.99326\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9123 - accuracy: 0.9180 - val_loss: 0.9944 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 483/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0972 - accuracy: 0.8727\n",
      "Epoch 00483: val_loss improved from 0.99326 to 0.99275, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.0674 - accuracy: 0.8852 - val_loss: 0.9927 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 484/500\n",
      "10/13 [======================>.......] - ETA: 0s - loss: 1.0215 - accuracy: 0.8800\n",
      "Epoch 00484: val_loss did not improve from 0.99275\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0544 - accuracy: 0.8934 - val_loss: 0.9929 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.9262\n",
      "Epoch 00485: val_loss improved from 0.99275 to 0.99144, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9044 - accuracy: 0.9262 - val_loss: 0.9914 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 486/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9075 - accuracy: 0.9273\n",
      "Epoch 00486: val_loss improved from 0.99144 to 0.99000, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.9666 - accuracy: 0.9016 - val_loss: 0.9900 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 487/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9818 - accuracy: 0.9000\n",
      "Epoch 00487: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0599 - accuracy: 0.8934 - val_loss: 0.9909 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 488/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0300 - accuracy: 0.8727\n",
      "Epoch 00488: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.0021 - accuracy: 0.8852 - val_loss: 0.9960 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 489/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9725 - accuracy: 0.9091\n",
      "Epoch 00489: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9706 - accuracy: 0.9098 - val_loss: 0.9965 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.9672\n",
      "Epoch 00490: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.8270 - accuracy: 0.9672 - val_loss: 0.9948 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 491/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9356 - accuracy: 0.9000\n",
      "Epoch 00491: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0279 - accuracy: 0.8934 - val_loss: 0.9936 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 492/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.9652 - accuracy: 0.9273\n",
      "Epoch 00492: val_loss did not improve from 0.99000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9503 - accuracy: 0.9262 - val_loss: 0.9907 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 493/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8671 - accuracy: 0.9250\n",
      "Epoch 00493: val_loss improved from 0.99000 to 0.98939, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.8930 - accuracy: 0.9098 - val_loss: 0.9894 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 494/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.8664 - accuracy: 0.9455\n",
      "Epoch 00494: val_loss did not improve from 0.98939\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.8838 - accuracy: 0.9180 - val_loss: 0.9916 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 495/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8520 - accuracy: 0.9417\n",
      "Epoch 00495: val_loss improved from 0.98939 to 0.98837, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9180 - accuracy: 0.9262 - val_loss: 0.9884 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 496/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9561 - accuracy: 0.9083\n",
      "Epoch 00496: val_loss improved from 0.98837 to 0.98338, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9522 - accuracy: 0.9098 - val_loss: 0.9834 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 497/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8901 - accuracy: 0.9167\n",
      "Epoch 00497: val_loss improved from 0.98338 to 0.98232, saving model to ././Influ_PC_6_model_n_best_weights.h5\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.8890 - accuracy: 0.9180 - val_loss: 0.9823 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 498/500\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9772 - accuracy: 0.9083\n",
      "Epoch 00498: val_loss did not improve from 0.98232\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.9810 - accuracy: 0.9016 - val_loss: 0.9839 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9197 - accuracy: 0.9262\n",
      "Epoch 00499: val_loss did not improve from 0.98232\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.9197 - accuracy: 0.9262 - val_loss: 0.9863 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 500/500\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 1.0075 - accuracy: 0.8818\n",
      "Epoch 00500: val_loss did not improve from 0.98232\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.0067 - accuracy: 0.8852 - val_loss: 0.9920 - val_accuracy: 0.8571 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "model, history = train_model(train_data,train_labels,val_data,val_labels,'Influ_PC_6_model_n', path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: input_3, Trainable: True\n",
      "Layer 1: conv1d_8, Trainable: True\n",
      "Layer 2: batch_normalization_8, Trainable: True\n",
      "Layer 3: dropout_4, Trainable: True\n",
      "Layer 4: conv1d_9, Trainable: True\n",
      "Layer 5: batch_normalization_9, Trainable: True\n",
      "Layer 6: conv1d_10, Trainable: True\n",
      "Layer 7: batch_normalization_10, Trainable: True\n",
      "Layer 8: conv1d_11, Trainable: True\n",
      "Layer 9: batch_normalization_11, Trainable: True\n",
      "Layer 10: dropout_5, Trainable: False\n",
      "Layer 11: global_max_pooling1d_2, Trainable: False\n",
      "Layer 12: dense_2, Trainable: False\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history ,'accuracy','val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history ,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "activation=tensorflow.keras.layers.LeakyReLU()\n",
    "model = load_model('Influ_PC_6_model_n_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9285714285714286,\n",
       " 'precision': 1.0,\n",
       " 'sensitivity': 0.8571428571428571,\n",
       " 'specificity': 1.0,\n",
       " 'f1': 0.923076923076923,\n",
       " 'mcc': 0.8660254037844387}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate\n",
    "metric_array(val_data, val_labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "test_AVP_data = PC_6('../data/Influ_pos_val.fasta', length=50)\n",
    "test_non_AVP_data = PC_6('../data/2neg_testing_uniprot_random_combined_17.fasta', length=50)\n",
    "test_AVP_array= np.array(list(test_AVP_data.values()))\n",
    "test_non_AVP_array = np.array(list(test_non_AVP_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature & labels\n",
    "test_features = np.concatenate((test_non_AVP_array,test_AVP_array),axis=0)\n",
    "test_labels = np.hstack((np.repeat(0, len(test_non_AVP_array)),np.repeat(1, len(test_AVP_array))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8235294117647058,\n",
       " 'precision': 0.9230769230769231,\n",
       " 'sensitivity': 0.7058823529411765,\n",
       " 'specificity': 0.9411764705882353,\n",
       " 'f1': 0.8000000000000002,\n",
       " 'mcc': 0.6657502859356826}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "metric_array(test_features, test_labels, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
